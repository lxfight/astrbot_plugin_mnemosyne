# é…ç½®è¿ç§»å’Œæ•°æ®è¿ç§»æœºåˆ¶è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

Mnemosyne æ’ä»¶ v0.6.0 æä¾›äº†å®Œæ•´çš„é…ç½®è¿ç§»å’Œæ•°æ®è¿ç§»æœºåˆ¶ï¼Œæ”¯æŒä»æ—§ç‰ˆæœ¬é…ç½®å‡çº§åˆ°æ–°ç‰ˆæœ¬ï¼Œä»¥åŠåœ¨ä¸åŒå‘é‡æ•°æ®åº“ä¹‹é—´è¿ç§»æ•°æ®ã€‚

## ğŸ”§ é…ç½®è¿ç§»æœºåˆ¶

### 1. é…ç½®è¿ç§»è§¦å‘æ–¹å¼

#### è‡ªåŠ¨æ£€æµ‹
```python
# åœ¨æ’ä»¶åˆå§‹åŒ–æ—¶è‡ªåŠ¨æ£€æµ‹
if self.config.get("_migration_version"):
    # å·²è¿ç§»ï¼Œæ— éœ€å¤„ç†
else:
    # éœ€è¦è¿ç§»
```

#### æ‰‹åŠ¨è§¦å‘
```bash
/memory migrate_config
```

### 2. é…ç½®è¿ç§»å®ç°

#### æ ¸å¿ƒé€»è¾‘ (`migrate_config_cmd_impl`)
```python
async def migrate_config_cmd_impl(self: "Mnemosyne", event: AstrMessageEvent):
    # 1. æ£€æŸ¥æ˜¯å¦å·²ç»è¿ç§»
    if self.config.get("_migration_version"):
        yield event.plain_result("âœ… é…ç½®å·²ç»æ˜¯æ–°æ ¼å¼ï¼Œæ— éœ€è¿ç§»ã€‚")
        return

    # 2. æ™ºèƒ½æ£€æµ‹æ•°æ®åº“ç±»å‹
    if "vector_database_type" not in self.config:
        if self.config.get("milvus_lite_path") or self.config.get("address"):
            self.config["vector_database_type"] = "milvus"
        else:
            self.config["vector_database_type"] = "faiss"

    # 3. æ·»åŠ  FAISS é…ç½®ç»“æ„
    if "faiss_config" not in self.config:
        self.config["faiss_config"] = {
            "faiss_data_path": "faiss_data",
            "faiss_index_type": "IndexFlatL2",
            "faiss_nlist": 100
        }

    # 4. æ·»åŠ åµŒå…¥æœåŠ¡é…ç½®
    if "embedding_provider_id" not in self.config:
        self.config["embedding_provider_id"] = ""

    # 5. æ ‡è®°è¿ç§»ç‰ˆæœ¬
    self.config["_migration_version"] = "0.6.0"
    self.config["_migration_date"] = datetime.now().isoformat()
```

#### é…ç½®ç»“æ„å˜æ›´

**æ—§é…ç½®æ ¼å¼**:
```json
{
  "embedding_service": "openai",
  "embedding_model": "text-embedding-ada-002",
  "embedding_key": "sk-xxx",
  "faiss_data_path": "faiss_data",
  "faiss_index_type": "IndexFlatL2",
  "milvus_lite_path": "milvus.db"
}
```

**æ–°é…ç½®æ ¼å¼**:
```json
{
  "vector_database_type": "faiss",
  "embedding_provider_id": "ç¡…åŸºå‡å›º",
  "faiss_config": {
    "faiss_data_path": "faiss_data",
    "faiss_index_type": "IndexFlatL2",
    "faiss_nlist": 100
  },
  "milvus_lite_path": "milvus.db",
  "_migration_version": "0.6.0",
  "_migration_date": "2024-06-23T15:30:00"
}
```

### 3. è·¯å¾„å¤„ç†æœºåˆ¶

#### è‡ªåŠ¨è·¯å¾„æ›´æ–° (`_update_config_paths`)
```python
def _update_config_paths(self, config: dict) -> dict:
    # 1. æ›´æ–° FAISS æ•°æ®è·¯å¾„
    faiss_config = config.get("faiss_config", {})
    if "faiss_data_path" in faiss_config:
        faiss_path = faiss_config["faiss_data_path"]
        if not os.path.isabs(faiss_path):
            # ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºåŸºäºæ’ä»¶æ•°æ®ç›®å½•çš„ç»å¯¹è·¯å¾„
            config["faiss_config"]["faiss_data_path"] = os.path.join(
                self.plugin_data_path, faiss_path
            )

    # 2. æ›´æ–° Milvus Lite è·¯å¾„
    if "milvus_lite_path" in config and config["milvus_lite_path"]:
        milvus_path = config["milvus_lite_path"]
        if not os.path.isabs(milvus_path):
            config["milvus_lite_path"] = os.path.join(
                self.plugin_data_path, milvus_path
            )
    
    return config
```

#### è·¯å¾„å¤„ç†è§„åˆ™
- **ç›¸å¯¹è·¯å¾„**: è‡ªåŠ¨è½¬æ¢ä¸ºåŸºäº `plugin_data_path` çš„ç»å¯¹è·¯å¾„
- **ç»å¯¹è·¯å¾„**: ä¿æŒä¸å˜
- **é»˜è®¤è·¯å¾„**: å¦‚æœæœªé…ç½®ï¼Œä½¿ç”¨é»˜è®¤ç›¸å¯¹è·¯å¾„

## ğŸ’¾ æ•°æ®è¿ç§»æœºåˆ¶

### 1. æ•°æ®è¿ç§»è§¦å‘æ–¹å¼

#### FAISS è¿ç§»
```bash
/memory migrate_to_faiss --confirm
```

#### Milvus è¿ç§»
```bash
/memory migrate_to_milvus --confirm
```

### 2. æ•°æ®è¿ç§»å®ç°

#### æ ¸å¿ƒè¿ç§»é€»è¾‘ (`VectorDatabaseFactory.migrate_data`)
```python
@staticmethod
def migrate_data(
    source_db: VectorDatabase,
    target_db: VectorDatabase,
    collection_name: str,
    batch_size: int = 1000,
) -> bool:
    try:
        # 1. æ£€æŸ¥æºé›†åˆæ˜¯å¦å­˜åœ¨
        if not source_db.has_collection(collection_name):
            logger.error(f"Source collection '{collection_name}' does not exist")
            return False

        # 2. è·å–æºé›†åˆçš„æ‰€æœ‰æ•°æ®
        all_data = source_db.query(
            collection_name=collection_name,
            filters="memory_id >= 0",  # è·å–æ‰€æœ‰è®°å½•
            output_fields=["*"],       # è·å–æ‰€æœ‰å­—æ®µ
            limit=None,
        )

        # 3. è·å–æºé›†åˆçš„ schema
        source_stats = source_db.get_collection_stats(collection_name)
        schema = {
            "vector_dim": source_stats.get("vector_dim", 1024),
            "fields": [],  # ç®€åŒ–çš„ schema
        }

        # 4. åœ¨ç›®æ ‡æ•°æ®åº“ä¸­åˆ›å»ºé›†åˆ
        if not target_db.create_collection(collection_name, schema):
            logger.error(f"Failed to create target collection '{collection_name}'")
            return False

        # 5. åˆ†æ‰¹è¿ç§»æ•°æ®
        total_records = len(all_data)
        migrated_count = 0

        for i in range(0, total_records, batch_size):
            batch_data = all_data[i : i + batch_size]
            
            if target_db.insert(collection_name, batch_data):
                migrated_count += len(batch_data)
                logger.info(f"Migrated {migrated_count}/{total_records} records")
            else:
                logger.error(f"Failed to migrate batch {i // batch_size + 1}")
                return False

        return True
    except Exception as e:
        logger.error(f"Data migration failed: {e}", exc_info=True)
        return False
```

#### è¿ç§»æµç¨‹å›¾
```mermaid
graph TD
    A[å¼€å§‹è¿ç§»] --> B[æ£€æŸ¥å½“å‰æ•°æ®åº“ç±»å‹]
    B --> C{æ˜¯å¦éœ€è¦è¿ç§»?}
    C -->|å¦| D[è¿”å›æ— éœ€è¿ç§»]
    C -->|æ˜¯| E[ç”¨æˆ·ç¡®è®¤]
    E --> F[æ£€æŸ¥æºæ•°æ®åº“è¿æ¥]
    F --> G[åˆ›å»ºç›®æ ‡æ•°æ®åº“å®ä¾‹]
    G --> H[éªŒè¯ç›®æ ‡æ•°æ®åº“é…ç½®]
    H --> I[è·å–æºæ•°æ®]
    I --> J[åˆ›å»ºç›®æ ‡é›†åˆ]
    J --> K[åˆ†æ‰¹è¿ç§»æ•°æ®]
    K --> L[æ›´æ–°é…ç½®]
    L --> M[å®Œæˆè¿ç§»]
```

### 3. å¼‚æ­¥è¿ç§»å¤„ç†

#### åå°æ‰§è¡Œ
```python
# åœ¨åå°æ‰§è¡Œè¿ç§»ï¼Œé¿å…é˜»å¡ç”¨æˆ·ç•Œé¢
success = await asyncio.get_event_loop().run_in_executor(
    None,
    lambda: VectorDatabaseFactory.migrate_data(
        source_db=self.vector_db,
        target_db=target_db,
        collection_name=self.collection_name,
        batch_size=1000,
    ),
)
```

#### è¿›åº¦åé¦ˆ
```python
# å®æ—¶åé¦ˆè¿ç§»è¿›åº¦
for i in range(0, total_records, batch_size):
    batch_data = all_data[i : i + batch_size]
    if target_db.insert(collection_name, batch_data):
        migrated_count += len(batch_data)
        logger.info(f"Migrated {migrated_count}/{total_records} records")
```

## ğŸ” è¿ç§»çŠ¶æ€æ£€æŸ¥

### çŠ¶æ€æŸ¥è¯¢å‘½ä»¤
```bash
/memory status
```

### çŠ¶æ€æ£€æŸ¥å®ç°
```python
async def migration_status_cmd_impl(self: "Mnemosyne", event: AstrMessageEvent):
    # 1. è·å–å½“å‰é…ç½®ä¿¡æ¯
    current_db_type = self.config.get("vector_database_type", "milvus")
    embedding_provider_id = self.config.get("embedding_provider_id", "")

    # 2. æ£€æŸ¥æ•°æ®åº“è¿æ¥çŠ¶æ€
    db_status = "âŒ æœªè¿æ¥"
    if self.vector_db and self.vector_db.is_connected():
        db_status = "âœ… å·²è¿æ¥"
        stats = self.vector_db.get_collection_stats(self.collection_name)
        # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯

    # 3. æ£€æŸ¥åµŒå…¥æœåŠ¡çŠ¶æ€
    embedding_status = "âŒ æœªåˆå§‹åŒ–"
    if self.embedding_adapter:
        embedding_status = "âœ… å·²åˆå§‹åŒ–"
        # æ˜¾ç¤ºåµŒå…¥æœåŠ¡è¯¦ç»†ä¿¡æ¯

    # 4. æ£€æŸ¥è¿ç§»ç‰ˆæœ¬
    migration_version = self.config.get("_migration_version", "")
    is_migrated = "âœ… å·²è¿ç§»åˆ° v0.6.0" if migration_version else "âš ï¸ å¯èƒ½éœ€è¦è¿ç§»"
```

## ğŸ›¡ï¸ å®‰å…¨æœºåˆ¶

### 1. ç¡®è®¤æœºåˆ¶
- æ‰€æœ‰å±é™©æ“ä½œéƒ½éœ€è¦ `--confirm` å‚æ•°
- æä¾›è¯¦ç»†çš„æ“ä½œè¯´æ˜å’Œé£é™©æç¤º

### 2. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
```python
# è¿ç§»å‰æ£€æŸ¥
if not source_db.has_collection(collection_name):
    return False

# è¿ç§»åéªŒè¯
if migrated_count != total_records:
    logger.warning("Migration count mismatch")
```

### 3. å›æ»šæœºåˆ¶
- ä¿ç•™åŸå§‹æ•°æ®ç›´åˆ°è¿ç§»ç¡®è®¤æˆåŠŸ
- æä¾›é…ç½®å›æ»šé€‰é¡¹
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è®°å½•

## ğŸ“Š è¿ç§»æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹å¤„ç†
- é»˜è®¤æ‰¹å¤„ç†å¤§å°: 1000 æ¡è®°å½•
- å¯é…ç½®çš„æ‰¹å¤„ç†å¤§å°
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–

### 2. å¼‚æ­¥å¤„ç†
- ä½¿ç”¨ `asyncio.get_event_loop().run_in_executor()`
- é¿å…é˜»å¡ä¸»çº¿ç¨‹
- æ”¯æŒå–æ¶ˆæ“ä½œ

### 3. è¿›åº¦ç›‘æ§
- å®æ—¶è¿›åº¦åé¦ˆ
- è¯¦ç»†çš„æ—¥å¿—è®°å½•
- é”™è¯¯æ¢å¤æœºåˆ¶

## ğŸ”§ é…ç½®éªŒè¯

### éªŒè¯å‘½ä»¤
```bash
/memory validate_config
```

### éªŒè¯å®ç°
```python
async def validate_config_cmd_impl(self: "Mnemosyne", event: AstrMessageEvent):
    # 1. éªŒè¯æ•°æ®åº“é…ç½®
    db_valid, db_error = VectorDatabaseFactory.validate_config(db_type, self.config)
    
    # 2. éªŒè¯åµŒå…¥æœåŠ¡é…ç½®
    embedding_valid, embedding_error = EmbeddingServiceFactory.validate_config(self.config)
    
    # 3. æ£€æŸ¥å¿…è¦é…ç½®é¡¹
    required_fields = ["LLM_providers"]
    missing_fields = [field for field in required_fields if not self.config.get(field)]
    
    # 4. ç»¼åˆè¯„ä¼°
    all_valid = db_valid and embedding_valid and not missing_fields
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. è¿ç§»å‰å‡†å¤‡
- ä½¿ç”¨ `/memory status` æ£€æŸ¥å½“å‰çŠ¶æ€
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
- å¤‡ä»½é‡è¦é…ç½®

### 2. è¿ç§»è¿‡ç¨‹
- é¿å…åœ¨è¿ç§»æœŸé—´è¿›è¡Œå…¶ä»–æ“ä½œ
- ç›‘æ§è¿ç§»è¿›åº¦å’Œæ—¥å¿—
- ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š

### 3. è¿ç§»åéªŒè¯
- ä½¿ç”¨ `/memory validate_config` éªŒè¯é…ç½®
- æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
- æµ‹è¯•åŸºæœ¬åŠŸèƒ½

### 4. æ•…éšœæ¢å¤
- æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
- æ£€æŸ¥é…ç½®æ–‡ä»¶
- å¿…è¦æ—¶å›æ»šåˆ°åŸå§‹é…ç½®

## ğŸ¯ å…·ä½“è¿ç§»å‘½ä»¤å®ç°

### FAISS è¿ç§»å‘½ä»¤ (`migrate_to_faiss_cmd_impl`)

```python
async def migrate_to_faiss_cmd_impl(
    self: "Mnemosyne", event: AstrMessageEvent, confirm: Optional[str] = None
):
    # 1. æ£€æŸ¥å½“å‰æ•°æ®åº“ç±»å‹
    current_db_type = self.config.get("vector_database_type", "milvus").lower()
    if current_db_type == "faiss":
        yield event.plain_result("âœ… å½“å‰å·²ç»ä½¿ç”¨ FAISS æ•°æ®åº“ï¼Œæ— éœ€è¿ç§»ã€‚")
        return

    # 2. ç¡®è®¤æ“ä½œ
    if confirm != "--confirm":
        yield event.plain_result(
            "âš ï¸ æ•°æ®è¿ç§»ç¡®è®¤ âš ï¸\n"
            "æ­¤æ“ä½œå°†æŠŠæ•°æ®ä» Milvus è¿ç§»åˆ° FAISS æ•°æ®åº“ã€‚\n"
            "è¿ç§»è¿‡ç¨‹ä¸­è¯·å‹¿è¿›è¡Œå…¶ä»–æ“ä½œã€‚\n\n"
            "å¦‚æœç¡®å®šè¦ç»§ç»­ï¼Œè¯·æ‰§è¡Œï¼š\n"
            "`/memory migrate_to_faiss --confirm`"
        )
        return

    # 3. æ‰§è¡Œè¿ç§»
    try:
        # åˆ›å»º FAISS æ•°æ®åº“å®ä¾‹
        faiss_config = self.config.copy()
        faiss_config["vector_database_type"] = "faiss"

        target_db = VectorDatabaseFactory.create_database(
            "faiss", faiss_config, self.embedding_adapter, self.logger
        )

        # æ‰§è¡Œæ•°æ®è¿ç§»
        success = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: VectorDatabaseFactory.migrate_data(
                source_db=self.vector_db,
                target_db=target_db,
                collection_name=self.collection_name,
                batch_size=1000,
            ),
        )

        if success:
            # æ›´æ–°é…ç½®
            self.config["vector_database_type"] = "faiss"
            yield event.plain_result("âœ… æ•°æ®è¿ç§»åˆ° FAISS å®Œæˆï¼")
        else:
            yield event.plain_result("âŒ æ•°æ®è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")

    except Exception as e:
        yield event.plain_result(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
```

### Milvus è¿ç§»å‘½ä»¤ (`migrate_to_milvus_cmd_impl`)

```python
async def migrate_to_milvus_cmd_impl(
    self: "Mnemosyne", event: AstrMessageEvent, confirm: Optional[str] = None
):
    # ç±»ä¼¼çš„å®ç°ï¼Œä½†ç›®æ ‡æ˜¯ Milvus æ•°æ®åº“
    current_db_type = self.config.get("vector_database_type", "milvus").lower()
    if current_db_type == "milvus":
        yield event.plain_result("âœ… å½“å‰å·²ç»ä½¿ç”¨ Milvus æ•°æ®åº“ï¼Œæ— éœ€è¿ç§»ã€‚")
        return

    # æ£€æŸ¥ Milvus é…ç½®
    if not self.config.get("milvus_lite_path") and not self.config.get("address"):
        yield event.plain_result(
            "âŒ ç¼ºå°‘ Milvus é…ç½®ã€‚è¯·å…ˆé…ç½® milvus_lite_path æˆ– addressã€‚"
        )
        return

    # æ‰§è¡Œè¿ç§»é€»è¾‘...
```

## ğŸ”„ è‡ªåŠ¨è¿ç§»æ£€æµ‹

### å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹
```python
def __init__(self, context: Context):
    # åœ¨æ’ä»¶åˆå§‹åŒ–æ—¶æ£€æµ‹æ˜¯å¦éœ€è¦è¿ç§»
    if not self.config.get("_migration_version"):
        self.logger.info("æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬é…ç½®ï¼Œå»ºè®®ä½¿ç”¨ /memory migrate_config è¿›è¡Œè¿ç§»")

    # æ£€æµ‹é…ç½®ç»“æ„
    if "faiss_data_path" in self.config and "faiss_config" not in self.config:
        self.logger.warning("æ£€æµ‹åˆ°æ—§çš„ FAISS é…ç½®ç»“æ„ï¼Œå»ºè®®è¿ç§»é…ç½®")
```

### å…¼å®¹æ€§å¤„ç†
```python
def _ensure_backward_compatibility(self):
    """ç¡®ä¿å‘åå…¼å®¹æ€§"""
    # å¦‚æœä½¿ç”¨æ—§çš„é…ç½®ç»“æ„ï¼Œè‡ªåŠ¨è½¬æ¢
    if "faiss_data_path" in self.config and "faiss_config" not in self.config:
        self.config["faiss_config"] = {
            "faiss_data_path": self.config.pop("faiss_data_path"),
            "faiss_index_type": self.config.pop("faiss_index_type", "IndexFlatL2"),
            "faiss_nlist": self.config.pop("faiss_nlist", 100),
        }
        self.logger.info("è‡ªåŠ¨è½¬æ¢æ—§çš„ FAISS é…ç½®ç»“æ„")
```

## ğŸ“‹ è¿ç§»æ£€æŸ¥æ¸…å•

### è¿ç§»å‰æ£€æŸ¥
- [ ] å½“å‰æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
- [ ] å¤‡ä»½é‡è¦é…ç½®æ–‡ä»¶
- [ ] ç¡®è®¤ç›®æ ‡æ•°æ®åº“é…ç½®æ­£ç¡®

### è¿ç§»è¿‡ç¨‹ç›‘æ§
- [ ] ç›‘æ§è¿ç§»è¿›åº¦æ—¥å¿—
- [ ] æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
- [ ] ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
- [ ] é¿å…å…¶ä»–æ“ä½œå¹²æ‰°

### è¿ç§»åéªŒè¯
- [ ] éªŒè¯æ•°æ®å®Œæ•´æ€§
- [ ] æµ‹è¯•åŸºæœ¬æŸ¥è¯¢åŠŸèƒ½
- [ ] æ£€æŸ¥é…ç½®æ–‡ä»¶æ›´æ–°
- [ ] ç¡®è®¤æ–°æ•°æ®åº“è¿æ¥æ­£å¸¸

## ğŸš¨ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### Q1: è¿ç§»è¿‡ç¨‹ä¸­æ–­æ€ä¹ˆåŠï¼Ÿ
**A**:
1. æ£€æŸ¥é”™è¯¯æ—¥å¿—ç¡®å®šä¸­æ–­åŸå› 
2. åŸå§‹æ•°æ®é€šå¸¸ä¸ä¼šè¢«åˆ é™¤
3. ä¿®å¤é—®é¢˜åé‡æ–°æ‰§è¡Œè¿ç§»å‘½ä»¤
4. å¿…è¦æ—¶æ‰‹åŠ¨æ¸…ç†ä¸å®Œæ•´çš„ç›®æ ‡æ•°æ®

### Q2: è¿ç§»åæ•°æ®ä¸¢å¤±ï¼Ÿ
**A**:
1. æ£€æŸ¥è¿ç§»æ—¥å¿—ä¸­çš„è®°å½•æ•°é‡
2. ä½¿ç”¨ `/memory list_records` éªŒè¯æ•°æ®
3. æ£€æŸ¥ç›®æ ‡æ•°æ®åº“çš„é›†åˆçŠ¶æ€
4. å¦‚æœç¡®å®ä¸¢å¤±ï¼Œä»å¤‡ä»½æ¢å¤

### Q3: é…ç½®è¿ç§»å¤±è´¥ï¼Ÿ
**A**:
1. æ‰‹åŠ¨æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼
2. ä½¿ç”¨ `/memory validate_config` éªŒè¯
3. å‚è€ƒæ–‡æ¡£æ‰‹åŠ¨è°ƒæ•´é…ç½®
4. é‡æ–°æ‰§è¡Œ `/memory migrate_config`

### Q4: æ€§èƒ½é—®é¢˜ï¼Ÿ
**A**:
1. è°ƒæ•´æ‰¹å¤„ç†å¤§å° (batch_size)
2. æ£€æŸ¥ç£ç›˜ I/O æ€§èƒ½
3. ç¡®ä¿è¶³å¤Ÿçš„å†…å­˜
4. è€ƒè™‘åœ¨ä½å³°æ—¶æ®µæ‰§è¡Œè¿ç§»

---

*æœ€åæ›´æ–°: 2024-06-23*
*é€‚ç”¨ç‰ˆæœ¬: v0.6.0+*
